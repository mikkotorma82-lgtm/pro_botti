from __future__ import annotations
import argparse, json, os
from pathlib import Path
import numpy as np, pandas as pd
from joblib import load
from core.io import load_history

ROOT = Path(__file__).resolve().parents[1]
DATA_DIR = ROOT / "data" / "history"
MODEL_DIR = ROOT / "models"
DEFAULT_FEATS = ["ret1","ret5","vol5","ema12","ema26","macd","rsi14","atr14","ema_gap"]

def _is_numeric_str(s: str) -> bool:
    s = str(s).strip()
    if s.startswith("-"):
        s = s[1:]
    return s.isdigit()

def _detect_unit(x: int) -> str:
    n = len(str(abs(int(x))))
    if n >= 18: return "ns"   # 19–20 numbers
    if n >= 15: return "us"   # 15–17
    if n >= 13: return "ms"   # 13–14
    return "s"                # <= 10 (normaalit epoch-sekunnit)

def to_utc_ts_and_iso(v):
    try:
        if isinstance(v, (pd.Timestamp, np.datetime64)):
            t = pd.to_datetime(v, utc=True)
        elif isinstance(v, (int, float, np.integer, np.floating)) or _is_numeric_str(v):
            x = int(float(v))
            unit = _detect_unit(x)
            t = pd.to_datetime(x, unit=unit, utc=True)
        else:
            t = pd.to_datetime(v, utc=True)
        if t.tzinfo is None:
            t = t.tz_localize("UTC")
        else:
            t = t.tz_convert("UTC")
        return int(t.timestamp()), t.isoformat()
    except Exception:
        return None, None

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--symbol", required=True)
    ap.add_argument("--tf", required=True)
    ap.add_argument("--limit_rows", type=int, default=2000)
    ap.add_argument("--thr_buy", type=float, default=0.10)
    ap.add_argument("--thr_sell", type=float, default=0.10)
    args = ap.parse_args()

    df = load_history(DATA_DIR, args.symbol, args.tf)
    if args.limit_rows and len(df) > args.limit_rows:
        df = df.tail(args.limit_rows)

    missing = [c for c in DEFAULT_FEATS if c not in df.columns]
    if missing:
        print(json.dumps({"symbol": args.symbol, "tf": args.tf, "error": f"missing features: {missing}"}))
        return

    X = df[DEFAULT_FEATS].tail(1).to_numpy()
    price = float(df["close"].iloc[-1]) if "close" in df.columns and len(df) else None

    model_path = MODEL_DIR / f"pro_{args.symbol}_{args.tf}.joblib"
    if not model_path.exists():
        print(json.dumps({"symbol": args.symbol, "tf": args.tf, "error": f"model not found: {model_path.name}"}))
        return
    clf = load(model_path)
    if not hasattr(clf, "predict_proba"):
        print(json.dumps({"symbol": args.symbol, "tf": args.tf, "error": "model has no predict_proba"}))
        return

    proba = clf.predict_proba(X)
    classes = list(getattr(clf, "classes_"))
    pmap = {str(classes[i]): float(proba[0, i]) for i in range(len(classes))}
    best_idx = int(np.argmax(proba[0]))
    try:
        s = int(classes[best_idx])
    except Exception:
        s = 0
    if s == 1 and pmap.get("1", 0.0) < args.thr_buy: s = 0
    if s == -1 and pmap.get("-1", 0.0) < args.thr_sell: s = 0

    ts, iso = (None, None)
    if "time" in df.columns and len(df):
        ts, iso = to_utc_ts_and_iso(df["time"].iloc[-1])

    out = {
        "symbol": args.symbol,
        "tf": args.tf,
        "time": ts,          # epoch seconds
        "time_iso": iso,     # ISO-UTC
        "price": price,
        "signal": int(s),
        "proba": pmap,
        "features_used": DEFAULT_FEATS,
    }
    print(json.dumps(out, ensure_ascii=False, indent=2))

if __name__ == "__main__":
    os.environ.setdefault("OMP_NUM_THREADS","1")
    os.environ.setdefault("MKL_NUM_THREADS","1")
    os.environ.setdefault("OPENBLAS_NUM_THREADS","1")
    os.environ.setdefault("NUMEXPR_MAX_THREADS","1")
    main()
