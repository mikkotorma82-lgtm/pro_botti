import os, sys, json, time, math, traceback, datetime as dt
from typing import Dict, Any, Tuple, Optional
import warnings
import numpy as np
import pandas as pd
from ohlcv_bridge import get_ohlcv

import numpy as np
import pandas as pd
# Valinnaiset kirjastot
try:
    import xgboost as xgb  # type: ignore
except Exception:
    xgb = None

try:
    import optuna  # type: ignore
except Exception:
    optuna = None

warnings.filterwarnings("ignore", category=UserWarning)

# Projektin moduulit
# Olettaen että nämä ovat olemassa (ne tulivat mukana projektissa):
# - instrument_loader.get_ohlcv(symbol, tf)
# - instrument_loader.available(symbols, tfs) (valinnainen)
# korvattu shimillä

MODELS_DIR = "/root/pro_botti/models"


# ----------------------------- apu: ympäristö -----------------------------

def _env_bool(key: str, default: bool = False) -> bool:
    v = os.environ.get(key)
    if v is None:
        return default
    return str(v).strip() in ("1", "true", "True", "YES", "yes", "on", "On")

def _env_float(key: str, default: float) -> float:
    try:
        return float(os.environ.get(key, default))
    except Exception:
        return default

def _env_int(key: str, default: int) -> int:
    try:
        return int(os.environ.get(key, default))
    except Exception:
        return default

def _news_windows_from_env() -> list[tuple[int, int]]:
    """
    Palauttaa minuutti-offset-ikkunat UTC-päivän sisällä [(min_start, min_end), ...].
    Esim: "CPI@13:30Z±30;FOMC@18:00Z±45" -> [(13*60+30-30, 13*60+30+30), (18*60-45, 18*60+45)]
    """
    raw = os.environ.get("NEWS_WINDOWS", "")  # puolipiste-erottelu
    res = []
    if not raw:
        return res
    parts = [p.strip() for p in raw.split(";") if p.strip()]
    for p in parts:
        try:
            at = p.split("@", 1)[1]
            hhmm, span = at.split("Z", 1)[0], p.split("±", 1)[1]
            hh, mm = hhmm.split(":")
            minute = int(hh) * 60 + int(mm)
            span = int(span)
            res.append((minute - span, minute + span))
        except Exception:
            continue
    return res


# ----------------------------- featurenrakennus -----------------------------

def _ema(a: pd.Series, n: int) -> pd.Series:
    return a.ewm(span=n, adjust=False).mean()

def _atr(df: pd.DataFrame, n: int = 14) -> pd.Series:
    high, low, close = df["high"], df["low"], df["close"]
    prev_close = close.shift(1)
    tr = pd.concat([(high - low).abs(),
                    (high - prev_close).abs(),
                    (low - prev_close).abs()], axis=1).max(axis=1)
    return tr.rolling(n, min_periods=n).mean()

def _rsi(close: pd.Series, n: int = 14) -> pd.Series:
    delta = close.diff()
    up = delta.clip(lower=0.0)
    down = -delta.clip(upper=0.0)
    roll_up = up.rolling(n, min_periods=n).mean()
    roll_down = down.rolling(n, min_periods=n).mean()
    rs = roll_up / roll_down.replace(0, np.nan)
    rsi = 100.0 - (100.0 / (1.0 + rs))
    return rsi

def _parkinson_rv(df: pd.DataFrame, n: int = 14) -> pd.Series:
    hl = (df["high"] / df["low"]).apply(lambda x: np.log(x) ** 2)
    k = 1.0 / (4.0 * np.log(2))
    return (k * hl).rolling(n, min_periods=n).mean()

def _htf_trend(close: pd.Series, w: int) -> pd.Series:
    ema_fast = _ema(close, max(5, w // 5))
    ema_slow = _ema(close, w)
    return np.sign(ema_fast - ema_slow)  # -1, 0, +1

def _vol_regime(atr: pd.Series) -> pd.Series:
    # suhteellinen ATR omaan mediaaniin
    rel = atr / atr.rolling(100, min_periods=50).median()
    bins = pd.qcut(rel.clip(upper=10.0).fillna(1.0), 3, labels=[0, 1, 2]).astype(float)
    return bins  # 0=low,1=med,2=high

def _news_dummy(idx: pd.DatetimeIndex) -> pd.Series:
    windows = _news_windows_from_env()
    if not windows:
        return pd.Series(index=idx, data=0.0)
    # mapataan päivän minuuttiin (UTC)
    mins = (idx.tz_convert("UTC") if idx.tz is not None else idx.tz_localize("UTC")).hour * 60 + \
           (idx.tz_convert("UTC") if idx.tz is not None else idx.tz_localize("UTC")).minute
    mask = np.zeros(len(idx), dtype=float)
    for s, e in windows:
        mask = np.logical_or(mask, np.logical_and(mins >= s, mins <= e))
    return pd.Series(mask.astype(float), index=idx)

def build_features(symbol: str, tf: str):
    """
    Palauttaa (X, y, close)
    y = +1 jos +1R saavutetaan ennen -1R (long-näkökulma), muuten 0.
    Malli oppii p(up). Short-puoli tulkitaan 1-p_up.
    """
    df = get_ohlcv(symbol, tf)  # odotetaan columns: open, high, low, close, volume; DatetimeIndex
    if df is None or len(df) < 500:
        raise ValueError(f"Ei dataa {symbol} {tf}")

    df = df.copy()
    df = df.dropna()

    # Perusfeats
    df["ema20"] = _ema(df["close"], 20)
    df["ema50"] = _ema(df["close"], 50)
    df["rsi14"] = _rsi(df["close"], 14)
    df["atr14"] = _atr(df, 14)
    df["rv_par14"] = _parkinson_rv(df, 14)

    # HTF-trendit: ~1D ja ~1W vaihtelu – luodaan ikkunoilla
    # (ei resamplata, vaan pidetään yksinkertaisena)
    day_w = 96 if tf == "15m" else (24 if tf == "1h" else 6 * 24)  # karkeat
    week_w = day_w * 5
    df["htf_day"] = _htf_trend(df["close"], max(10, day_w))
    df["htf_week"] = _htf_trend(df["close"], max(50, week_w))

    # Volatiiliregiimi
    df["vol_reg"] = _vol_regime(df["atr14"])

    # Uutisikkuna dummy
    df["news"] = _news_dummy(df.index)

    # Jotta ei-äärettömät
    df = df.replace([np.inf, -np.inf], np.nan).dropna()

    # Labelointi R-mallilla (vastaa liveä)
    stop_r = _env_float("STOP_R", 1.0)         # 1R stop
    target_r = _env_float("TARGET_R", 1.0)     # 1R tp
    lookahead = _env_int("LOOKAHEAD_BARS", 1)  # kuinka moneen kynttilään katsotaan

    # Riskin mitta: käytetään ATR:ää (tasapainoinen)
    risk = df["atr14"].shift(1)  # käytä tiedossa olevaa
    entry = df["close"]
    tp = entry + target_r * risk
    sl = entry - stop_r * risk

    # "toteutunut ensin" -logiikka
    future_high = df["high"].shift(-1).rolling(lookahead, min_periods=1).max()
    future_low = df["low"].shift(-1).rolling(lookahead, min_periods=1).min()

    hit_tp = (future_high >= tp)
    hit_sl = (future_low <= sl)

    y = (hit_tp & ~hit_sl) | ((hit_tp & hit_sl) & ((tp - entry) < (entry - sl)))  # jos molemmat osuu, kumpi osuu "lähempänä"
    y = y.astype(int)

    # Feats-matriisi
    feats = ["ema20", "ema50", "rsi14", "atr14", "rv_par14", "htf_day", "htf_week", "vol_reg", "news"]
    X = df[feats].astype(float).copy()
    y = y.loc[X.index]
    close = df["close"].loc[X.index]

    # Puhdista front/back
    X = X.iloc[100:]  # jätä lämpeämiset pois
    y = y.loc[X.index]
    close = close.loc[X.index]

    return X, y.values, close


# ----------------------------- PF-metriikka -----------------------------

def _pf_from_preds(y_true: np.ndarray,
                   p_up: np.ndarray,
                   thr: float,
                   cost_bps: float,
                   slippage_bps: float) -> tuple[float, float, int]:
    """
    Arvioi PF & WR annetulla kynnyksellä. Yksinkertaistus:
    - kun p_up >= thr -> long-signaali, muussa tapauksessa ei oteta longia (short arvioidaan erikseen omalla kynnyksellä)
    - voitto = +1R, tappio = -1R, kustannukset = (cost+slippage) bps per toteutunut treidi
    Palauttaa (pf, wr, n_trades)
    """
    sel = p_up >= thr
    n = int(sel.sum())
    if n == 0:
        return 0.0, 0.0, 0
    wins = int((y_true[sel] == 1).sum())
    losses = n - wins
    wr = wins / max(1, n)

    # kustannukset bps → R:ksi. Oletetaan että 1R ~ %-liike ~ ei tarkkaa, mutta pidetään lineaarinen:
    # käytännössä laskee PF:ää hieman joka treidiltä.
    cost_r = (cost_bps + slippage_bps) / 10000.0
    gross_win = wins * 1.0
    gross_loss = losses * 1.0
    # vähennä kustannus joka toteutuneesta treidistä
    net_win = max(0.0, gross_win - n * cost_r)
    net_loss = max(1e-9, gross_loss + n * cost_r)  # estä jakaja 0

    pf = net_win / net_loss if net_loss > 0 else 0.0
    return pf, wr, n


def _grid_best_thr(y_true: np.ndarray,
                   p_up: np.ndarray,
                   cost_bps: float,
                   slippage_bps: float,
                   thr_grid: np.ndarray | None = None) -> dict:
    if thr_grid is None:
        thr_grid = np.linspace(0.50, 0.99, 50)
    best = {"thr": 0.5, "pf": 0.0, "wr": 0.0, "n": 0}
    for thr in thr_grid:
        pf, wr, n = _pf_from_preds(y_true, p_up, thr, cost_bps, slippage_bps)
        if n >= 50 and pf > best["pf"]:
            best = {"thr": float(thr), "pf": float(pf), "wr": float(wr), "n": int(n)}
    return best


# ----------------------------- mallitus -----------------------------

def _train_model(X: pd.DataFrame, y: np.ndarray, use_xgb: bool) -> tuple[object, list[str]]:
    feats = list(X.columns)
    if use_xgb and xgb is not None:
        model = xgb.XGBClassifier(
            n_estimators=300, max_depth=4, learning_rate=0.05, subsample=0.9, colsample_bytree=0.9,
            reg_lambda=1.0, reg_alpha=0.0, objective="binary:logistic", n_jobs=4, tree_method="hist"
        )
        model.fit(X.values, y)
        return model, feats
    else:
        from sklearn.ensemble import GradientBoostingClassifier
        model = GradientBoostingClassifier(
            n_estimators=300, max_depth=3, learning_rate=0.05, subsample=0.9
        )
        model.fit(X.values, y)
        return model, feats

def _predict_proba(model: object, X: pd.DataFrame) -> np.ndarray:
    try:
        return model.predict_proba(X.values)[:, 1]
    except Exception:
        # xgboost Booster?
        try:
            d = xgb.DMatrix(X.values)  # type: ignore
            return model.predict(d)  # type: ignore
        except Exception:
            # fallback: decision_function -> sigmoid
            from scipy.special import expit
            df = getattr(model, "decision_function")(X.values)
            return expit(df)


# ----------------------------- walk-forward -----------------------------

def _walk_forward_pf(X: pd.DataFrame,
                     y: np.ndarray,
                     cost_bps: float,
                     slippage_bps: float,
                     use_xgb: bool) -> tuple[object, dict, np.ndarray]:
    """
    Yksinkertainen rolling-origin: 4 osaan -> 3 foldia (train 1->val 2, train 1-2->val 3, train 1-3->val 4).
    Optimoidaan thr long-puolelle (short tehdään elannon puolella peiliksi).
    Palauttaa: final_model, best_meta, p_up_out_of_fold
    """
    n = len(X)
    if n < 1200:
        # varmistetaan jonkinlainen määrä
        k1 = n // 4
        splits = [(0, k1, 2*k1), (0, 2*k1, 3*k1), (0, 3*k1, n)]
    else:
        k1 = n // 4
        splits = [(0, k1, 2*k1), (0, 2*k1, 3*k1), (0, 3*k1, n)]

    p_oo = np.full(n, np.nan)
    thrs = []
    wrs = []
    pfs = []
    for (s_tr, e_tr, e_val) in splits:
        Xtr, ytr = X.iloc[s_tr:e_tr], y[s_tr:e_tr]
        Xva, yva = X.iloc[e_tr:e_val], y[e_tr:e_val]
        if len(Xva) < 50 or len(Xtr) < 200:
            continue
        model, feats = _train_model(Xtr, ytr, use_xgb=use_xgb)
        p = _predict_proba(model, Xva)
        best = _grid_best_thr(yva, p, cost_bps, slippage_bps)
        # tallenna out-of-fold p
        p_oo[e_tr:e_val] = p
        thrs.append(best["thr"]); wrs.append(best["wr"]); pfs.append(best["pf"])

    # Yhdistä
    p_oo = np.where(np.isnan(p_oo), np.nanmedian(p_oo), p_oo)
    thr_long = float(np.median(thrs)) if thrs else 0.55
    wr = float(np.mean(wrs)) if wrs else 0.5
    pf = float(np.median(pfs)) if pfs else 1.0

    # Treenaa final-malli kaikella
    final_model, feats = _train_model(X, y, use_xgb=use_xgb)
    meta = {"thr_long": thr_long, "wr": wr, "pf": pf, "features": feats}
    return final_model, meta, p_oo


# ----------------------------- tallennus -----------------------------

def _model_path(symbol: str, tf: str) -> str:
    return os.path.join(MODELS_DIR, f"model_{symbol}_{tf}.bin")

def _pro_path(symbol: str, tf: str) -> str:
    return os.path.join(MODELS_DIR, f"pro_{symbol}_{tf}.json")

def _load_old_pf(symbol: str, tf: str) -> float:
    pth = _pro_path(symbol, tf)
    try:
        with open(pth, "r", encoding="utf-8") as f:
            return float(json.load(f).get("pf", 0.0))
    except Exception:
        return 0.0

def _save_pro(symbol: str, tf: str, meta: dict):
    os.makedirs(MODELS_DIR, exist_ok=True)
    pth = _pro_path(symbol, tf)
    with open(pth, "w", encoding="utf-8") as f:
        json.dump(meta, f, ensure_ascii=False, indent=2)


# ----------------------------- päälogiikka -----------------------------

def train_symbol_tf(symbol: str, tf: str) -> tuple[dict, bool]:
    """
    Palauttaa (meta, ok). ok=False jos mallia ei päivitetä.
    """
    # Kulut & slippage (bps)
    cost_bps = _env_float(f"COST_BPS_{symbol}", _env_float("COST_BPS_DEFAULT", 1.5))
    slippage_bps = _env_float(f"SLIPPAGE_BPS_{symbol}", _env_float("SLIPPAGE_BPS_DEFAULT", 2.0))

    X, y, close = build_features(symbol, tf)

    # Walk-forward & thr haku
    use_xgb = _env_bool("USE_XGB", True)
    model, meta, p_oo = _walk_forward_pf(X, y, cost_bps, slippage_bps, use_xgb=use_xgb)

    # Arvioi short-kynnys peilaamalla (tarvittaessa voidaan tehdä erillinen short-malli)
    # Käytetään symmetriaa: jos malli arvioi p_up, niin shortissa käytä samaa thr_short = thr_long,
    # ja p_short = 1 - p_up (live hoitaa jo tämän mallin).
    thr_long = float(meta["thr_long"])
    thr_short = float(meta["thr_long"])

    # Lopullinen PF-estimaatti OOF-predikoilla
    pf_est, wr_est, n_tr = _grid_best_thr(y, p_oo, cost_bps, slippage_bps).values()

    # Hyväksyntäraja
    min_pf_accept = _env_float("MIN_PF_ACCEPT", 1.00)
    prev_pf = _load_old_pf(symbol, tf)
    accept = (pf_est >= min_pf_accept) and (pf_est >= prev_pf - 1e-9)

    trained_at = datetime.utcnow().replace(tzinfo=timezone.utc).isoformat()

    pro_meta = {
        "symbol": symbol,
        "tf": tf,
        "thr_long": thr_long,
        "thr_short": thr_short,
        "pf": float(pf_est),
        "wr": float(wr_est),
        "n": int(n_tr),
        "features": len(meta.get("features", [])),
        "feature_names": meta.get("features", []),
        "cost_bps": float(cost_bps),
        "slippage_bps": float(slippage_bps),
        "trained_at": trained_at,
        "notes": "PF-optimized thresholds with costs & slippage; mirrored short."
    }

    if accept:
        _save_pro(symbol, tf, pro_meta)
        print(f"✅ Koulutus valmis {symbol} {tf}: pf={pf_est:.2f} wr={wr_est*100:.1f}% thr={thr_long:.3f} feats={len(meta.get('features', []))}")
        return pro_meta, True
    else:
        print(f"⚠️  Hylätty {symbol} {tf}: pf={pf_est:.2f} (< min {min_pf_accept:.2f} tai < edellinen {prev_pf:.2f}) – ei päivitetty.")
        return pro_meta, False


def loop():
    # Konfig
    symbols = os.environ.get("SYMBOLS", "AAPL,ADAUSDT,BTCUSD,BTCUSDT,ETHUSD,ETHUSDT,EURUSD,GBPUSD,NVDA,SOLUSDT,TSLA,US100,US500,XRPUSDT")
    SYMBOLS = [s.strip() for s in symbols.split(",") if s.strip()]
    tfs = os.environ.get("TFS", "15m,1h,4h")
    TFS = [t.strip() for t in tfs.split(",") if t.strip()]

    interval_min = _env_int("TRAIN_INTERVAL_MIN", 180)
    lookahead = _env_int("LOOKAHEAD_BARS", 1)
    use_xgb = _env_bool("USE_XGB", True)

    print(f"[{datetime.utcnow().isoformat()}] Trainer käynnissä. SYMBOLS={SYMBOLS} TFS={TFS} interval={interval_min}min lookahead={lookahead} xgb={use_xgb}")

    while True:
        for sym in SYMBOLS:
            for tf in TFS:
                try:
                    meta, ok = train_symbol_tf(sym, tf)
                except Exception as e:
                    traceback.print_exc()
                    print(f"[ERROR] {sym} {tf}: {e}")
                    continue
        # odotus
        time.sleep(max(60, interval_min * 60))


if __name__ == "__main__":
    try:
        loop()
    except KeyboardInterrupt:
        pass