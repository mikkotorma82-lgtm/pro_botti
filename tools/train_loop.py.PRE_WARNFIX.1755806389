import os, argparse, json, yaml
from pathlib import Path
import numpy as np
import pandas as pd

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from tools.lr_safe import SafeLogistic as LogisticRegression
from sklearn.metrics import classification_report
from joblib import dump

# --- polut ---
ROOT = Path(__file__).resolve().parents[1]
DATA_DIR = ROOT / "data" / "history"
MODEL_DIR = ROOT / "models"
REPORT_DIR = ROOT / "data" / "reports"
MODEL_DIR.mkdir(parents=True, exist_ok=True)
REPORT_DIR.mkdir(parents=True, exist_ok=True)

# --- apurit ---
def load_cfg(path: Path) -> dict:
    with open(path, "r") as f:
        return yaml.safe_load(f)

def load_df(symbol: str, tf: str) -> pd.DataFrame:
    p = DATA_DIR / f"{symbol}_{tf}.csv"
    if not p.exists():
        raise FileNotFoundError(p)
    df = pd.read_csv(p); $'DROP_TIME=["time","date","datetime","timestamp","open_time","close_time"]
df.drop(columns=[c for c in DROP_TIME if c in df.columns], inplace=True, errors="ignore")
df = df.select_dtypes(include="number")'
    df = df.sort_values("time").reset_index(drop=True)
    for col in ["open","high","low","close","volume"]:
        if col not in df.columns:
            raise ValueError(f"{p} missing column {col}")
    return df

# --- indikaattorit (kevyt, ei riippuvuuksia) ---
def ema(s, span):
    return s.ewm(span=span, adjust=False).mean()

def rsi(close, period=14):
    delta = close.diff()
    up = (delta.clip(lower=0)).ewm(alpha=1/period, adjust=False).mean()
    down = (-delta.clip(upper=0)).ewm(alpha=1/period, adjust=False).mean()
    rs = up / (down + 1e-12)
    return 100 - (100 / (1 + rs))

def atr(df, period=14):
    hl = df["high"] - df["low"]
    hc = (df["high"] - df["close"].shift()).abs()
    lc = (df["low"] - df["close"].shift()).abs()
    tr = pd.concat([hl, hc, lc], axis=1).max(axis=1)
    return tr.ewm(alpha=1/period, adjust=False).mean()

def make_features(df: pd.DataFrame) -> pd.DataFrame:
    z = df.copy()
    z["ret1"] = z["close"].pct_change()
    z["ret5"] = z["close"].pct_change(5)
    z["vol5"] = z["ret1"].rolling(48, min_periods=12).std()
    z["ema12"] = ema(z["close"], 12)
    z["ema26"] = ema(z["close"], 26)
    z["macd"]  = z["ema12"] - z["ema26"]
    z["rsi14"] = rsi(z["close"], 14)
    z["atr14"] = atr(z, 14) / (z["close"] + 1e-12)
    z["ema_gap"] = (z["close"] - z["ema12"]) / (z["ema12"] + 1e-12)
    z = z.dropna().reset_index(drop=True)
    return z

def label_future(df: pd.DataFrame, horizon=1, thr_pos=0.0, thr_neg=0.0):
    fut = df["close"].shift(-horizon) / df["close"] - 1.0
    y = np.where(fut > thr_pos, 1, np.where(fut < -thr_neg, -1, 0))
    return pd.Series(y, index=df.index)

def walk_splits(n: int, n_splits: int = 5):
    # aikapohjaiset splitit: [0..train_end) treeni, [train_end..val_end) validi
    if n_splits < 1:
        return
    fold = max(1, n // (n_splits + 1))
    for k in range(n_splits):
        train_end = fold * (k + 1)
        val_end   = fold * (k + 2)
        tr = np.arange(0, min(train_end, n))
        va = np.arange(min(train_end, n), min(val_end, n))
        if len(tr) == 0 or len(va) == 0:
            continue
        yield tr, va

# --- varsinainen treenaus ---
def fit_one(symbol: str, tf: str, cfg: dict) -> dict:
    df = load_df(symbol, tf)
    df_feat = make_features(df)

    horizon = int((cfg.get("train") or {}).get("horizon_bars", 1))
    y = label_future(df_feat, horizon=horizon, thr_pos=0.0, thr_neg=0.0)

    # FEATS guard
    FEATS = (cfg.get("features") or [])
    if not FEATS:
        blacklist = {"close","y","target","label","future_y","future_label"}
        FEATS = [c for c in df_feat.columns if c not in blacklist]
    else:
        FEATS = [f for f in FEATS if f in df_feat.columns]
        if not FEATS:
            blacklist = {"close","y","target","label","future_y","future_label"}
            FEATS = [c for c in df_feat.columns if c not in blacklist]
    if not FEATS:
        FEATS = [c for c in df_feat.columns if c != "close"]

    X = df_feat[FEATS].values
    mask = ~np.isnan(y.values)
    X, y = X[mask], y.values[mask]
    n = len(y)
    if n < 100:
        raise RuntimeError(f"{symbol} {tf}: liian v채h채n dataa ({n})")

    pipe = Pipeline([
        ("scaler", StandardScaler()),
        ("clf", LogisticRegression(max_iter=1000, C=1.0, multi_class="auto"))
    ])

    # CV-raportit
    reports = []
    n_splits = int((cfg.get("train") or {}).get("n_splits", 5))
    for tr, va in walk_splits(n, n_splits):
        Xtr, ytr = X[tr], y[tr]
        Xva, yva = X[va], y[va]
        pipe.fit(Xtr, ytr)
        yhat = pipe.predict(Xva)
        rep = classification_report(yva, yhat, output_dict=True, zero_division=0)
        reports.append(rep)

    # lopullinen malli (j채t채 2*horizon loppuun testausta varten)
    cut = max(0, n - 2*horizon)
    pipe.fit(X[:cut], y[:cut])

    # tallennus
    model_path = MODEL_DIR / f"ml_{symbol}_{tf}.joblib"
    meta_path  = MODEL_DIR / f"ml_{symbol}_{tf}.json"
    meta = {"features": FEATS, "horizon": int(horizon), "cut": int(cut)}
    dump({"pipeline": pipe, "features": FEATS}, model_path)
    with open(meta_path, "w") as f:
        json.dump(meta, f, indent=2)
    print(f"[OK] saved {model_path.name} + {meta_path.name}")

    # pikaraportti
    avg_acc = float(np.mean([r["accuracy"] for r in reports])) if reports else None
    out = {
        "symbol": symbol,
        "tf": tf,
        "n": int(n),
        "avg_cv_accuracy": avg_acc,
        "model_path": str(model_path),
        "meta_path": str(meta_path),
    }
    rep_path = REPORT_DIR / f"train_{symbol}_{tf}.json"
    with open(rep_path, "w") as f:
        json.dump(out, f, indent=2)
    print(f"[REP] {rep_path}")
    return out

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--config", default="config.yaml")
    ap.add_argument("--symbols", nargs="*", default=None)
    ap.add_argument("--tfs", nargs="*", default=None)
    args = ap.parse_args()

    cfg = load_cfg(Path(args.config))

    # symbolit
    symbols = args.symbols
    if not symbols:
        symbols = (cfg.get("market", {}) or {}).get("symbols", [])
    if not symbols:
        symbols = (cfg.get("live", {}) or {}).get("symbols", [])
    if not symbols:
        raise SystemExit("Ei symboleita (market.symbols tai --symbols)")

    # timeframe:t
    tfs = args.tfs or (cfg.get("train", {}) or {}).get("timeframes", ["15m","1h","4h"])

    for s in symbols:
        for tf in tfs:
            try:
                fit_one(s, tf, cfg)
            except Exception as e:
                print(f"[FAIL] {s} {tf}: {e}")

if __name__ == "__main__":
    main()
