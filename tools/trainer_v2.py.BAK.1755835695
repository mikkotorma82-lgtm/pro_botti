import os, argparse, json, math, yaml
from pathlib import Path
import numpy as np
import pandas as pd
from joblib import dump
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from tools.lr_safe import SafeLogistic as LogisticRegression
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.metrics import classification_report
from sklearn.model_selection import TimeSeriesSplit

# xgboost (valinnainen)
try:
    from xgboost import XGBClassifier
    HAS_XGB = True
except Exception:
    HAS_XGB = False

ROOT = Path(__file__).resolve().parents[1]
DATA_DIR = ROOT / "data" / "history"
MODEL_DIR = ROOT / "models_v2"
REPORT_DIR = ROOT / "data" / "reports_v2"
MODEL_DIR.mkdir(parents=True, exist_ok=True)
REPORT_DIR.mkdir(parents=True, exist_ok=True)

def load_cfg(path: Path) -> dict:
    with open(path, "r") as f:
        return yaml.safe_load(f)

def load_df(symbol: str, tf: str) -> pd.DataFrame:
    p = DATA_DIR / f"{symbol}_{tf}.csv"
    if not p.exists():
        raise FileNotFoundError(p)
    df = pd.read_csv(p).sort_values("time").reset_index(drop=True); $'DROP_TIME=["time","date","datetime","timestamp","open_time","close_time"]
df.drop(columns=[c for c in DROP_TIME if c in df.columns], inplace=True, errors="ignore")
df = df.select_dtypes(include="number")'
    for col in ["open","high","low","close","volume"]:
        if col not in df.columns:
            raise ValueError(f"{p} missing column {col}")
    return df

# ---- perus indikaattorit
def ema(s, span): return s.ewm(span=span, adjust=False).mean()
def rsi(close, period=14):
    d = close.diff()
    up = (d.clip(lower=0)).ewm(alpha=1/period, adjust=False).mean()
    dn = (-d.clip(upper=0)).ewm(alpha=1/period, adjust=False).mean()
    rs = up / (dn + 1e-12)
    return 100 - (100/(1+rs))
def atr(df, period=14):
    hl = df["high"] - df["low"]
    hc = (df["high"] - df["close"].shift()).abs()
    lc = (df["low"] - df["close"].shift()).abs()
    tr = pd.concat([hl, hc, lc], axis=1).max(axis=1)
    return tr.ewm(alpha=1/period, adjust=False).mean()
def adx(df, period=14):
    up = df["high"].diff()
    dn = -df["low"].diff()
    plus_dm = np.where((up>dn) & (up>0), up, 0.0)
    minus_dm = np.where((dn>up) & (dn>0), dn, 0.0)
    tr = atr(df, period) * 0 + ((df["high"]-df["low"]).rolling(1).max()) # dummy shape
    tr = (df["high"]-df["low"]).combine((df["high"]-df["close"].shift()).abs(), max)\
         .combine((df["low"]-df["close"].shift()).abs(), max)
    atr14 = tr.ewm(alpha=1/period, adjust=False).mean()
    plus_di = 100 * pd.Series(plus_dm).ewm(alpha=1/period, adjust=False).mean() / (atr14+1e-12)
    minus_di = 100 * pd.Series(minus_dm).ewm(alpha=1/period, adjust=False).mean() / (atr14+1e-12)
    dx = ( (plus_di - minus_di).abs() / ((plus_di + minus_di)+1e-12) ) * 100
    return dx.ewm(alpha=1/period, adjust=False).mean()

def bollinger(close, period=20, k=2.0):
    ma = close.rolling(period).mean()
    sd = close.rolling(period).std()
    upper = ma + k*sd
    lower = ma - k*sd
    bw = (upper - lower) / (ma + 1e-12)
    pct = (close - lower) / ((upper - lower) + 1e-12)
    return upper, lower, bw, pct

def obv(close, volume):
    dir = np.sign(close.diff().fillna(0))
    return (volume * dir).fillna(0).cumsum()

def make_features(df: pd.DataFrame) -> (pd.DataFrame, list[str]):
    z = df.copy()
    z["ret1"]  = z["close"].pct_change()
    z["ret3"]  = z["close"].pct_change(3)
    z["ret5"]  = z["close"].pct_change(5)
    z["vol20"] = z["ret1"].rolling(20, min_periods=10).std()
    z["ema12"] = ema(z["close"], 12)
    z["ema26"] = ema(z["close"], 26)
    z["macd"]  = z["ema12"] - z["ema26"]
    z["rsi14"] = rsi(z["close"], 14)
    z["atr14"] = atr(z, 14) / (z["close"] + 1e-12)
    z["adx14"] = adx(z, 14)
    ub, lb, bbw, bbp = bollinger(z["close"], 20, 2.0)
    z["bb_bw"] = bbw
    z["bb_pos"] = bbp
    z["obv"] = obv(z["close"], z["volume"])
    z["ema_gap"] = (z["close"] - z["ema12"]) / (z["ema12"] + 1e-12)
    # S/R tasot (rolling pivot)
    roll = 50
    z["sup"] = z["low"].rolling(roll, min_periods=10).min()
    z["res"] = z["high"].rolling(roll, min_periods=10).max()
    z["sr_dist"] = np.minimum((z["close"]-z["sup"])/(z["close"]+1e-12),
                              (z["res"]-z["close"])/(z["close"]+1e-12))
    # trend score: ema-slope + adx
    z["ema12_slope"] = z["ema12"].diff()
    z["trend_score"] = (np.tanh(z["ema12_slope"]/ (z["close"]*1e-4 + 1e-12)) + (z["adx14"]/100.0))
    z = z.replace([np.inf,-np.inf], np.nan).dropna().reset_index(drop=True)
    feats = ["ret1","ret3","ret5","vol20","ema12","ema26","macd","rsi14","atr14",
             "adx14","bb_bw","bb_pos","obv","ema_gap","sup","res","sr_dist","ema12_slope","trend_score"]
    return z, feats

def label_future(df: pd.DataFrame, horizon=1, thr_pos=0.0, thr_neg=0.0):
    fut = df["close"].shift(-horizon) / df["close"] - 1.0
    y = np.where(fut > thr_pos, 1, np.where(fut < -thr_neg, -1, 0))
    return pd.Series(y, index=df.index)

def fit_one(symbol: str, tf: str, cfg: dict):
    df = load_df(symbol, tf)
    df_feat, FEATS = make_features(df)

    horizon = int((cfg.get("train", {}) or {}).get("horizon_bars", 1))
    y = label_future(df_feat, horizon=horizon, thr_pos=0.0, thr_neg=0.0)
    mask = ~np.isnan(y.values)
    X = df_feat[FEATS].values[mask]
    y = y.values[mask]
    n = len(y)
    if n < 300:
        raise RuntimeError(f"{symbol} {tf}: liian vähän dataa ({n})")

    # mallit
    base_lr = ("lr", Pipeline([
        ("scaler", StandardScaler()),
        ("clf", LogisticRegression(max_iter=2000, C=1.0))
    ]))
    rf = ("rf", RandomForestClassifier(
        n_estimators=300, max_depth=None, min_samples_leaf=3, n_jobs=-1, random_state=42))
    models = [base_lr, rf]
    if HAS_XGB:
        xgb = ("xgb", XGBClassifier(
            n_estimators=400, max_depth=5, learning_rate=0.05,
            subsample=0.8, colsample_bytree=0.8, reg_lambda=1.0,
            objective="multi:softprob", num_class=3, n_jobs=4, tree_method="hist",
            random_state=42))
        models.append(xgb)

    # Ensemblen runko
    # Huom: VotingClassifier ei skaalaa sisäisiä Piipeline-sisältöjä automaattisesti,
    # mutta meillä LR:llä scaler pipeline sisällä.
    estimators = [(name, mdl if isinstance(mdl, Pipeline) else mdl) for name, mdl in models]
    # Jos XGB puuttuu, soft-voting toimii kahdella jäsenelläkin
    ensemble = VotingClassifier(estimators=estimators, voting="soft", n_jobs=-1)

    # Aikajaksollinen CV
    n_splits = int((cfg.get("train", {}) or {}).get("n_splits", 5))
    tscv = TimeSeriesSplit(n_splits=n_splits)
    reports = []
    for tr_idx, va_idx in tscv.split(X):
        Xtr, Xva = X[tr_idx], X[va_idx]
        ytr, yva = y[tr_idx], y[va_idx]
        ensemble.fit(Xtr, ytr)
        yhat = ensemble.predict(Xva)
        rep = classification_report(yva, yhat, output_dict=True, zero_division=0)
        reports.append(rep)

    # Lopullinen malli
    cut = max(0, n - 2*horizon)
    ensemble.fit(X[:cut], y[:cut])

    # Talleta
    model_path = MODEL_DIR / f"pro_{symbol}_{tf}.joblib"
    meta_path  = MODEL_DIR / f"pro_{symbol}_{tf}.json"
    meta = {
        "features": FEATS,
        "horizon": int(horizon),
        "cut": int(cut),
        "models": [name for name,_ in models],
        "has_xgb": bool(HAS_XGB),
    }
    dump({"pipeline": ensemble, "features": FEATS}, model_path)
    with open(meta_path, "w") as f: json.dump(meta, f, indent=2)
    print(f"[OK v2] saved {model_path.name} + {meta_path.name}")

    avg_acc = float(np.mean([r["accuracy"] for r in reports])) if reports else None
    out = {
        "symbol": symbol, "tf": tf, "n": int(n),
        "avg_cv_accuracy": avg_acc,
        "model_path": str(model_path),
        "meta_path": str(meta_path),
    }
    rep_path = REPORT_DIR / f"train_v2_{symbol}_{tf}.json"
    with open(rep_path, "w") as f: json.dump(out, f, indent=2)
    print(f"[REP v2] {rep_path}")
    return out

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--config", default="config.yaml")
    ap.add_argument("--symbols", nargs="*", default=None)
    ap.add_argument("--tfs", nargs="*", default=None)
    args = ap.parse_args()

    cfg = load_cfg(Path(args.config))
    symbols = args.symbols or (cfg.get("market", {}) or {}).get("symbols", []) \
              or (cfg.get("live", {}) or {}).get("symbols", [])
    if not symbols:
        raise SystemExit("Ei symboleita (market.symbols tai --symbols)")

    tfs = args.tfs or (cfg.get("train", {}) or {}).get("timeframes", ["15m","1h","4h"])

    for s in symbols:
        for tf in tfs:
            try:
                fit_one(s, tf, cfg)
            except Exception as e:
                print(f"[FAIL v2] {s} {tf}: {e}")

if __name__ == "__main__":
    main()
